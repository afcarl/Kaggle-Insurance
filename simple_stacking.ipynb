{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = '' # your folder\n",
    "\n",
    "import pandas as pd\n",
    "train=pd.read_csv(base_path + 'train.csv')\n",
    "test=pd.read_csv(base_path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_16_bin ps_ind_17_bin\n",
      "ps_ind_16_bin ps_ind_18_bin\n",
      "ps_ind_17_bin ps_ind_16_bin\n",
      "ps_ind_17_bin ps_ind_18_bin\n",
      "ps_ind_18_bin ps_ind_16_bin\n",
      "ps_ind_18_bin ps_ind_17_bin\n"
     ]
    }
   ],
   "source": [
    "train['ps_ind_0609_bin'] = train.apply(lambda x: 1 if x['ps_ind_06_bin'] == 1 else (2 if x['ps_ind_07_bin'] == 1 else \n",
    "(\n",
    "3 if x['ps_ind_08_bin'] == 1 else (4 if x['ps_ind_09_bin'] == 1 else 5)\n",
    "\n",
    ")), axis = 1)\n",
    "\n",
    "test['ps_ind_0609_bin'] = test.apply(lambda x: 1 if x['ps_ind_06_bin'] == 1 else (2 if x['ps_ind_07_bin'] == 1 else \n",
    "(\n",
    "3 if x['ps_ind_08_bin'] == 1 else (4 if x['ps_ind_09_bin'] == 1 else 5)\n",
    "\n",
    ")), axis = 1)\n",
    "\n",
    "train.drop(['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin'], axis = 1, inplace = True)\n",
    "\n",
    "test.drop(['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin'], axis = 1, inplace = True)\n",
    "\n",
    "train['ps_car_13'] = (train['ps_car_13']*train['ps_car_13']* 48400).round(0)\n",
    "\n",
    "test['ps_car_13'] = (test['ps_car_13']*test['ps_car_13']* 48400).round(0)\n",
    "\n",
    "train['ps_car_12'] = (train['ps_car_12']*train['ps_car_12']).round(4) * 10000\n",
    "\n",
    "test['ps_car_12'] = (test['ps_car_12']*test['ps_car_12']).round(4) * 10000\n",
    "\n",
    "for c in train[[c for c in train.columns if 'bin' in c]].columns:\n",
    "    for cc in train[[c for c in train.columns if 'bin' in c]].columns:\n",
    "            if train[train[cc] * train[c] == 0].shape[0] == train.shape[0]:\n",
    "                print(c, cc)\n",
    "\n",
    "train['ps_ind_161718_bin'] = train.apply(lambda x: 1 if x['ps_ind_16_bin'] == 1 else\n",
    "                                        (2 if x['ps_ind_17_bin'] == 1 else 3), axis = 1\n",
    "                                        )\n",
    "\n",
    "test['ps_ind_161718_bin'] = test.apply(lambda x: 1 if x['ps_ind_16_bin'] == 1 else\n",
    "                                        (2 if x['ps_ind_17_bin'] == 1 else 3), axis = 1\n",
    "                                        )\n",
    "\n",
    "train.drop(['ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin'], axis = 1, inplace = True)\n",
    "\n",
    "test.drop(['ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin'], axis = 1, inplace = True)\n",
    "\n",
    "train.to_csv(base_path + 'train_p.csv', index = False)\n",
    "\n",
    "test.to_csv(base_path + 'test_p.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n",
      "(595212, 34) (892816, 33)\n",
      " xgb kfold: 1  of  5 : \n",
      "[0]\ttrain-gini:0.198944\tvalid-gini:0.207771\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 10 rounds.\n",
      "[10]\ttrain-gini:0.242451\tvalid-gini:0.23631\n",
      "[20]\ttrain-gini:0.247742\tvalid-gini:0.237284\n",
      "[30]\ttrain-gini:0.258204\tvalid-gini:0.244316\n",
      "[40]\ttrain-gini:0.274173\tvalid-gini:0.256681\n",
      "[50]\ttrain-gini:0.287652\tvalid-gini:0.263266\n",
      "[60]\ttrain-gini:0.296775\tvalid-gini:0.2681\n",
      "[70]\ttrain-gini:0.304583\tvalid-gini:0.270837\n",
      "[80]\ttrain-gini:0.310406\tvalid-gini:0.273019\n",
      "[90]\ttrain-gini:0.315519\tvalid-gini:0.274764\n",
      "[100]\ttrain-gini:0.319895\tvalid-gini:0.276049\n",
      "[110]\ttrain-gini:0.323956\tvalid-gini:0.276949\n",
      "[120]\ttrain-gini:0.327344\tvalid-gini:0.277822\n",
      "[130]\ttrain-gini:0.330701\tvalid-gini:0.277986\n",
      "Stopping. Best iteration:\n",
      "[126]\ttrain-gini:0.329063\tvalid-gini:0.278292\n",
      "\n",
      " xgb kfold: 2  of  5 : \n",
      "[0]\ttrain-gini:0.199074\tvalid-gini:0.192664\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 10 rounds.\n",
      "[10]\ttrain-gini:0.241227\tvalid-gini:0.23318\n",
      "Stopping. Best iteration:\n",
      "[6]\ttrain-gini:0.243621\tvalid-gini:0.237963\n",
      "\n",
      " xgb kfold: 3  of  5 : \n",
      "[0]\ttrain-gini:0.201478\tvalid-gini:0.197478\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 10 rounds.\n",
      "[10]\ttrain-gini:0.23826\tvalid-gini:0.228284\n",
      "[20]\ttrain-gini:0.249501\tvalid-gini:0.239298\n",
      "[30]\ttrain-gini:0.261849\tvalid-gini:0.248214\n",
      "[40]\ttrain-gini:0.276706\tvalid-gini:0.257139\n",
      "[50]\ttrain-gini:0.287053\tvalid-gini:0.263764\n",
      "[60]\ttrain-gini:0.297119\tvalid-gini:0.269304\n",
      "[70]\ttrain-gini:0.304296\tvalid-gini:0.27286\n",
      "[80]\ttrain-gini:0.310081\tvalid-gini:0.275688\n",
      "[90]\ttrain-gini:0.315027\tvalid-gini:0.277117\n",
      "[100]\ttrain-gini:0.319707\tvalid-gini:0.278064\n",
      "[110]\ttrain-gini:0.324392\tvalid-gini:0.278136\n",
      "[120]\ttrain-gini:0.328573\tvalid-gini:0.279526\n",
      "[130]\ttrain-gini:0.332009\tvalid-gini:0.280207\n",
      "Stopping. Best iteration:\n",
      "[128]\ttrain-gini:0.331187\tvalid-gini:0.280356\n",
      "\n",
      " xgb kfold: 4  of  5 : \n",
      "[0]\ttrain-gini:0.190118\tvalid-gini:0.186711\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 10 rounds.\n",
      "[10]\ttrain-gini:0.237832\tvalid-gini:0.224092\n",
      "[20]\ttrain-gini:0.245741\tvalid-gini:0.229662\n",
      "[30]\ttrain-gini:0.259525\tvalid-gini:0.241768\n",
      "[40]\ttrain-gini:0.275399\tvalid-gini:0.256211\n",
      "[50]\ttrain-gini:0.285772\tvalid-gini:0.265215\n",
      "[60]\ttrain-gini:0.294771\tvalid-gini:0.270668\n",
      "[70]\ttrain-gini:0.302417\tvalid-gini:0.275402\n",
      "[80]\ttrain-gini:0.308218\tvalid-gini:0.278146\n",
      "[90]\ttrain-gini:0.313748\tvalid-gini:0.280379\n",
      "[100]\ttrain-gini:0.319169\tvalid-gini:0.282961\n",
      "[110]\ttrain-gini:0.323733\tvalid-gini:0.283945\n",
      "[120]\ttrain-gini:0.327366\tvalid-gini:0.283799\n",
      "Stopping. Best iteration:\n",
      "[112]\ttrain-gini:0.324367\tvalid-gini:0.284312\n",
      "\n",
      " xgb kfold: 5  of  5 : \n",
      "[0]\ttrain-gini:0.198517\tvalid-gini:0.187643\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 10 rounds.\n",
      "[10]\ttrain-gini:0.242265\tvalid-gini:0.230058\n",
      "[20]\ttrain-gini:0.25164\tvalid-gini:0.237463\n",
      "[30]\ttrain-gini:0.258009\tvalid-gini:0.241762\n",
      "[40]\ttrain-gini:0.277315\tvalid-gini:0.253555\n",
      "[50]\ttrain-gini:0.289332\tvalid-gini:0.259487\n",
      "[60]\ttrain-gini:0.299123\tvalid-gini:0.264399\n",
      "[70]\ttrain-gini:0.305668\tvalid-gini:0.266376\n",
      "[80]\ttrain-gini:0.312176\tvalid-gini:0.267847\n",
      "[90]\ttrain-gini:0.317911\tvalid-gini:0.269941\n",
      "[100]\ttrain-gini:0.322227\tvalid-gini:0.270586\n",
      "[110]\ttrain-gini:0.326601\tvalid-gini:0.271531\n",
      "[120]\ttrain-gini:0.330311\tvalid-gini:0.271907\n",
      "[130]\ttrain-gini:0.334386\tvalid-gini:0.271595\n",
      "Stopping. Best iteration:\n",
      "[124]\ttrain-gini:0.331802\tvalid-gini:0.272006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "\n",
    "print('loading files...')\n",
    "train = pd.read_csv(base_path+'train_p.csv', na_values=-1)\n",
    "test = pd.read_csv(base_path+'test_p.csv', na_values=-1)\n",
    "col_to_drop = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "train = train.drop(col_to_drop, axis=1)  \n",
    "test = test.drop(col_to_drop, axis=1)  \n",
    "\n",
    "for c in train.select_dtypes(include=['float64']).columns:\n",
    "    train[c]=train[c].astype(np.float32)\n",
    "    test[c]=test[c].astype(np.float32)\n",
    "for c in train.select_dtypes(include=['int64']).columns[2:]:\n",
    "    train[c]=train[c].astype(np.int8)\n",
    "    test[c]=test[c].astype(np.int8)    \n",
    "\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "# custom objective function (similar to auc)\n",
    "\n",
    "def gini(y, pred):\n",
    "    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(y) + 1) / 2.\n",
    "    return gs / len(y)\n",
    "\n",
    "def gini_xgb(pred, y):\n",
    "    y = y.get_label()\n",
    "    return 'gini', gini(y, pred) / gini(y, y)\n",
    "\n",
    "def gini_lgb(preds, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = gini(y, preds) / gini(y, y)\n",
    "    return 'gini', score, True\n",
    "\n",
    "# xgb\n",
    "params = {'eta': 0.1, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, \n",
    "          'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent': False}\n",
    "\n",
    "X = train.drop(['id', 'target'], axis=1)\n",
    "features = X.columns\n",
    "X = X.values\n",
    "y = train['target'].values\n",
    "sub=test['id'].to_frame()\n",
    "sub['target']=0\n",
    "\n",
    "sub_train = train['id'].to_frame()\n",
    "sub_train['target']=0\n",
    "\n",
    "nrounds= 200 #10**6  # need to change to 2000\n",
    "kfold = 5  # need to change to 5\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=0)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(' xgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    d_train = xgb.DMatrix(X_train, y_train) \n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid) \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=10, \n",
    "                          feval=gini_xgb, maximize=True, verbose_eval=10)\n",
    "    sub['target'] += xgb_model.predict(xgb.DMatrix(test[features].values), \n",
    "                        ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n",
    "    \n",
    "    sub_train['target'] += xgb_model.predict(xgb.DMatrix(train[features].values), \n",
    "                        ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n",
    "    \n",
    "gc.collect()\n",
    "sub.head(2)\n",
    "\n",
    "sub.to_csv(base_path+'test_sub_xgb.csv', index=False, float_format='%.5f')\n",
    "sub_train.to_csv(base_path+'train_sub_xgb.csv', index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lgb kfold: 1  of  5 : \n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\tvalid_0's auc: 0.623345\tvalid_0's gini: 0.24667\n",
      "[20]\tvalid_0's auc: 0.627064\tvalid_0's gini: 0.254126\n",
      "[30]\tvalid_0's auc: 0.627838\tvalid_0's gini: 0.255675\n",
      "[40]\tvalid_0's auc: 0.631762\tvalid_0's gini: 0.263524\n",
      "[50]\tvalid_0's auc: 0.634841\tvalid_0's gini: 0.269682\n",
      "[60]\tvalid_0's auc: 0.636169\tvalid_0's gini: 0.272339\n",
      "[70]\tvalid_0's auc: 0.637842\tvalid_0's gini: 0.275685\n",
      "[80]\tvalid_0's auc: 0.638769\tvalid_0's gini: 0.277538\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.638863\tvalid_0's gini: 0.277727\n",
      " lgb kfold: 2  of  5 : \n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\tvalid_0's auc: 0.621524\tvalid_0's gini: 0.243062\n",
      "[20]\tvalid_0's auc: 0.626615\tvalid_0's gini: 0.25323\n",
      "[30]\tvalid_0's auc: 0.629257\tvalid_0's gini: 0.258515\n",
      "[40]\tvalid_0's auc: 0.634333\tvalid_0's gini: 0.268666\n",
      "[50]\tvalid_0's auc: 0.637239\tvalid_0's gini: 0.274478\n",
      "[60]\tvalid_0's auc: 0.639251\tvalid_0's gini: 0.278502\n",
      "[70]\tvalid_0's auc: 0.641425\tvalid_0's gini: 0.282849\n",
      "[80]\tvalid_0's auc: 0.642107\tvalid_0's gini: 0.284213\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.642161\tvalid_0's gini: 0.284322\n",
      " lgb kfold: 3  of  5 : \n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\tvalid_0's auc: 0.619487\tvalid_0's gini: 0.238931\n",
      "[20]\tvalid_0's auc: 0.62325\tvalid_0's gini: 0.246495\n",
      "[30]\tvalid_0's auc: 0.628138\tvalid_0's gini: 0.256274\n",
      "[40]\tvalid_0's auc: 0.631452\tvalid_0's gini: 0.262905\n",
      "[50]\tvalid_0's auc: 0.634674\tvalid_0's gini: 0.269348\n",
      "[60]\tvalid_0's auc: 0.636778\tvalid_0's gini: 0.273555\n",
      "[70]\tvalid_0's auc: 0.638671\tvalid_0's gini: 0.277342\n",
      "[80]\tvalid_0's auc: 0.639221\tvalid_0's gini: 0.278442\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.639301\tvalid_0's gini: 0.278603\n",
      " lgb kfold: 4  of  5 : \n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\tvalid_0's auc: 0.620726\tvalid_0's gini: 0.241431\n",
      "[20]\tvalid_0's auc: 0.626425\tvalid_0's gini: 0.252847\n",
      "[30]\tvalid_0's auc: 0.628429\tvalid_0's gini: 0.256858\n",
      "[40]\tvalid_0's auc: 0.634256\tvalid_0's gini: 0.268511\n",
      "[50]\tvalid_0's auc: 0.637949\tvalid_0's gini: 0.275898\n",
      "[60]\tvalid_0's auc: 0.641049\tvalid_0's gini: 0.282097\n",
      "[70]\tvalid_0's auc: 0.642841\tvalid_0's gini: 0.285682\n",
      "[80]\tvalid_0's auc: 0.643274\tvalid_0's gini: 0.286548\n",
      "[90]\tvalid_0's auc: 0.643541\tvalid_0's gini: 0.287083\n",
      "[100]\tvalid_0's auc: 0.643858\tvalid_0's gini: 0.287716\n",
      "[110]\tvalid_0's auc: 0.643829\tvalid_0's gini: 0.287658\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.643953\tvalid_0's gini: 0.287906\n",
      " lgb kfold: 5  of  5 : \n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\tvalid_0's auc: 0.618781\tvalid_0's gini: 0.237567\n",
      "[20]\tvalid_0's auc: 0.623495\tvalid_0's gini: 0.246995\n",
      "[30]\tvalid_0's auc: 0.625686\tvalid_0's gini: 0.251375\n",
      "[40]\tvalid_0's auc: 0.62935\tvalid_0's gini: 0.258699\n",
      "[50]\tvalid_0's auc: 0.631388\tvalid_0's gini: 0.262775\n",
      "[60]\tvalid_0's auc: 0.633977\tvalid_0's gini: 0.267953\n",
      "[70]\tvalid_0's auc: 0.635249\tvalid_0's gini: 0.270498\n",
      "[80]\tvalid_0's auc: 0.636141\tvalid_0's gini: 0.272281\n",
      "[90]\tvalid_0's auc: 0.636469\tvalid_0's gini: 0.272937\n",
      "[100]\tvalid_0's auc: 0.636933\tvalid_0's gini: 0.273866\n",
      "[110]\tvalid_0's auc: 0.636606\tvalid_0's gini: 0.273212\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.636933\tvalid_0's gini: 0.273866\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.024575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    target\n",
       "0   0  0.024575\n",
       "1   1  0.027148"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lgb\n",
    "sub['target']=0\n",
    "sub_train['target']=0\n",
    "\n",
    "params = {'metric': 'auc', 'learning_rate' : 0.1, 'max_depth':8, 'max_bin':10,  'objective': 'binary', \n",
    "          'feature_fraction': 0.8,'bagging_fraction':0.9,'bagging_freq':5,  'min_data': 500}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=1)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(' lgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
    "    X_train, X_eval = X[train_index], X[test_index]\n",
    "    y_train, y_eval = y[train_index], y[test_index]\n",
    "    lgb_model = lgb.train(params, lgb.Dataset(X_train, label=y_train), nrounds, \n",
    "                  lgb.Dataset(X_eval, label=y_eval), verbose_eval=10, \n",
    "                  feval=gini_lgb, early_stopping_rounds=10)\n",
    "    sub['target'] += lgb_model.predict(test[features].values, \n",
    "                        num_iteration=lgb_model.best_iteration) / (kfold)\n",
    "    sub_train['target'] += lgb_model.predict(train[features].values, \n",
    "                        num_iteration=lgb_model.best_iteration) / (kfold)\n",
    "    \n",
    "sub.to_csv(base_path+'test_sub_lgb.csv', index=False, float_format='%.5f') \n",
    "sub_train.to_csv(base_path+'train_sub_lgb.csv', index=False, float_format='%.5f')\n",
    "\n",
    "gc.collect()\n",
    "sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.264810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.360729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.463984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.026748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.588131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    target\n",
       "0   0  0.264810\n",
       "1   1  0.360729\n",
       "2   2  0.463984\n",
       "3   3  0.026748\n",
       "4   4  0.588131"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['id', 'target']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    target     stack     final\n",
      "0   0  0.264810  0.047145  0.325295\n",
      "1   1  0.360729  0.044300  0.344407\n",
      "2   2  0.463984  0.042049  0.372029\n",
      "3   3  0.026748  0.031275  0.038791\n",
      "4   4  0.588131  0.063401  0.607644\n"
     ]
    }
   ],
   "source": [
    "# new_df = pd.concat([test[['id', 'target']], stack1[['target']].rename(columns = {'target' : 'stack'})], axis = 1)\n",
    "# #new_df['final'] = np.mean([new_df['target'], new_df['stack']], axis = 1)\n",
    "# new_df['final'] = (new_df['target'].rank() + new_df['stack'].rank())/(2 * test.shape[0])\n",
    "# print(new_df.head())\n",
    "# new_df.columns = ['id', 'new_stack', 'stack1', 'target']\n",
    "# new_df[['id', 'target']].to_csv(base_path + 'rank_avg_lgbm_xgb_stack1.csv.gz', index = False, compression = 'gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerjadoshi/anaconda2/envs/fastai/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/neerjadoshi/anaconda2/envs/fastai/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/neerjadoshi/anaconda2/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module '_catboost' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "32\n",
      "(446409, 136) (148803, 136)\n",
      "Borders for float features generated\n",
      "0:\tlearn 0.547204263\ttest 0.5446748932\tbestTest 0.5446748932\t\ttotal: 950ms\tremaining: 3m 8s\n",
      "1:\tlearn 0.573248505\ttest 0.5731519818\tbestTest 0.5731519818\t\ttotal: 1.87s\tremaining: 3m 4s\n",
      "2:\tlearn 0.5915055485\ttest 0.592701179\tbestTest 0.592701179\t\ttotal: 2.74s\tremaining: 3m\n",
      "3:\tlearn 0.6052177179\ttest 0.6026552012\tbestTest 0.6026552012\t\ttotal: 3.67s\tremaining: 2m 59s\n",
      "4:\tlearn 0.611776931\ttest 0.6084025222\tbestTest 0.6084025222\t\ttotal: 4.61s\tremaining: 2m 59s\n",
      "5:\tlearn 0.6127940259\ttest 0.6102924295\tbestTest 0.6102924295\t\ttotal: 5.52s\tremaining: 2m 58s\n",
      "6:\tlearn 0.6124746553\ttest 0.6101776241\tbestTest 0.6102924295\t\ttotal: 6.17s\tremaining: 2m 50s\n",
      "7:\tlearn 0.6120952734\ttest 0.6101082714\tbestTest 0.6102924295\t\ttotal: 7.06s\tremaining: 2m 49s\n",
      "8:\tlearn 0.6130767979\ttest 0.6103475635\tbestTest 0.6103475635\t\ttotal: 7.8s\tremaining: 2m 45s\n",
      "9:\tlearn 0.6139701019\ttest 0.6113433246\tbestTest 0.6113433246\t\ttotal: 8.72s\tremaining: 2m 45s\n",
      "10:\tlearn 0.6136147532\ttest 0.6099339863\tbestTest 0.6113433246\t\ttotal: 9.61s\tremaining: 2m 45s\n",
      "11:\tlearn 0.6160116399\ttest 0.6120765975\tbestTest 0.6120765975\t\ttotal: 10.6s\tremaining: 2m 45s\n",
      "12:\tlearn 0.618241668\ttest 0.6130898768\tbestTest 0.6130898768\t\ttotal: 11.5s\tremaining: 2m 44s\n",
      "13:\tlearn 0.6196398037\ttest 0.6136433489\tbestTest 0.6136433489\t\ttotal: 12.4s\tremaining: 2m 44s\n",
      "14:\tlearn 0.6210968397\ttest 0.6147889124\tbestTest 0.6147889124\t\ttotal: 13.3s\tremaining: 2m 43s\n",
      "15:\tlearn 0.6238671966\ttest 0.6171253163\tbestTest 0.6171253163\t\ttotal: 14.2s\tremaining: 2m 42s\n",
      "16:\tlearn 0.6242669981\ttest 0.6169154561\tbestTest 0.6171253163\t\ttotal: 15.1s\tremaining: 2m 42s\n",
      "17:\tlearn 0.6239888892\ttest 0.6174339735\tbestTest 0.6174339735\t\ttotal: 16s\tremaining: 2m 41s\n",
      "18:\tlearn 0.6251171651\ttest 0.6188997331\tbestTest 0.6188997331\t\ttotal: 16.9s\tremaining: 2m 40s\n",
      "19:\tlearn 0.6260362461\ttest 0.6204864835\tbestTest 0.6204864835\t\ttotal: 17.7s\tremaining: 2m 39s\n",
      "20:\tlearn 0.6263312133\ttest 0.6214965897\tbestTest 0.6214965897\t\ttotal: 18.6s\tremaining: 2m 38s\n",
      "21:\tlearn 0.6282251756\ttest 0.6236770079\tbestTest 0.6236770079\t\ttotal: 19.5s\tremaining: 2m 37s\n",
      "22:\tlearn 0.6290364184\ttest 0.6246166835\tbestTest 0.6246166835\t\ttotal: 20.4s\tremaining: 2m 36s\n",
      "23:\tlearn 0.6290906625\ttest 0.6249193102\tbestTest 0.6249193102\t\ttotal: 21.3s\tremaining: 2m 35s\n",
      "24:\tlearn 0.6298235428\ttest 0.6257739188\tbestTest 0.6257739188\t\ttotal: 22s\tremaining: 2m 34s\n",
      "25:\tlearn 0.6303873467\ttest 0.6260934771\tbestTest 0.6260934771\t\ttotal: 22.9s\tremaining: 2m 33s\n",
      "26:\tlearn 0.6305359766\ttest 0.6264825165\tbestTest 0.6264825165\t\ttotal: 23.8s\tremaining: 2m 32s\n",
      "27:\tlearn 0.6319157915\ttest 0.6276264535\tbestTest 0.6276264535\t\ttotal: 24.6s\tremaining: 2m 31s\n",
      "28:\tlearn 0.6328791642\ttest 0.6283262373\tbestTest 0.6283262373\t\ttotal: 25.5s\tremaining: 2m 30s\n",
      "29:\tlearn 0.6330394782\ttest 0.6284371003\tbestTest 0.6284371003\t\ttotal: 26.4s\tremaining: 2m 29s\n",
      "30:\tlearn 0.6334199026\ttest 0.6286648884\tbestTest 0.6286648884\t\ttotal: 27.3s\tremaining: 2m 28s\n",
      "31:\tlearn 0.6341106452\ttest 0.6292488873\tbestTest 0.6292488873\t\ttotal: 28.2s\tremaining: 2m 28s\n",
      "32:\tlearn 0.6346080181\ttest 0.6295541134\tbestTest 0.6295541134\t\ttotal: 29.1s\tremaining: 2m 27s\n",
      "33:\tlearn 0.6349295133\ttest 0.6295794213\tbestTest 0.6295794213\t\ttotal: 30s\tremaining: 2m 26s\n",
      "34:\tlearn 0.6351310715\ttest 0.6296610313\tbestTest 0.6296610313\t\ttotal: 30.8s\tremaining: 2m 25s\n",
      "35:\tlearn 0.6352935866\ttest 0.6297004199\tbestTest 0.6297004199\t\ttotal: 31.7s\tremaining: 2m 24s\n",
      "36:\tlearn 0.6357146525\ttest 0.629957065\tbestTest 0.629957065\t\ttotal: 32.6s\tremaining: 2m 23s\n",
      "37:\tlearn 0.6358894889\ttest 0.6302699518\tbestTest 0.6302699518\t\ttotal: 33.5s\tremaining: 2m 22s\n",
      "38:\tlearn 0.6360840749\ttest 0.6302742411\tbestTest 0.6302742411\t\ttotal: 34.4s\tremaining: 2m 22s\n",
      "39:\tlearn 0.6368105547\ttest 0.6305019164\tbestTest 0.6305019164\t\ttotal: 35.3s\tremaining: 2m 21s\n",
      "40:\tlearn 0.6368788783\ttest 0.6307183567\tbestTest 0.6307183567\t\ttotal: 36.1s\tremaining: 2m 20s\n",
      "41:\tlearn 0.6374094471\ttest 0.6309976526\tbestTest 0.6309976526\t\ttotal: 36.9s\tremaining: 2m 18s\n",
      "42:\tlearn 0.6383319294\ttest 0.6315883016\tbestTest 0.6315883016\t\ttotal: 37.8s\tremaining: 2m 18s\n",
      "43:\tlearn 0.639054023\ttest 0.6318879478\tbestTest 0.6318879478\t\ttotal: 38.8s\tremaining: 2m 17s\n",
      "44:\tlearn 0.6391577621\ttest 0.6319205294\tbestTest 0.6319205294\t\ttotal: 39.4s\tremaining: 2m 15s\n",
      "45:\tlearn 0.6395516726\ttest 0.6321147694\tbestTest 0.6321147694\t\ttotal: 40.3s\tremaining: 2m 14s\n",
      "46:\tlearn 0.6398921086\ttest 0.6322965544\tbestTest 0.6322965544\t\ttotal: 41.2s\tremaining: 2m 14s\n",
      "47:\tlearn 0.6400143273\ttest 0.6323468254\tbestTest 0.6323468254\t\ttotal: 42.1s\tremaining: 2m 13s\n",
      "48:\tlearn 0.6401811023\ttest 0.6322947005\tbestTest 0.6323468254\t\ttotal: 43s\tremaining: 2m 12s\n",
      "49:\tlearn 0.6408245161\ttest 0.632561791\tbestTest 0.632561791\t\ttotal: 44s\tremaining: 2m 11s\n",
      "50:\tlearn 0.6412292077\ttest 0.6326681592\tbestTest 0.6326681592\t\ttotal: 44.9s\tremaining: 2m 11s\n",
      "51:\tlearn 0.6415531941\ttest 0.6327041239\tbestTest 0.6327041239\t\ttotal: 45.8s\tremaining: 2m 10s\n",
      "52:\tlearn 0.6416119485\ttest 0.6327276842\tbestTest 0.6327276842\t\ttotal: 46.7s\tremaining: 2m 9s\n",
      "53:\tlearn 0.6419725158\ttest 0.6326133818\tbestTest 0.6327276842\t\ttotal: 47.6s\tremaining: 2m 8s\n",
      "54:\tlearn 0.6425239141\ttest 0.6328078363\tbestTest 0.6328078363\t\ttotal: 48.5s\tremaining: 2m 7s\n",
      "55:\tlearn 0.6428379577\ttest 0.6329560642\tbestTest 0.6329560642\t\ttotal: 49.4s\tremaining: 2m 7s\n",
      "56:\tlearn 0.6430806404\ttest 0.6331061057\tbestTest 0.6331061057\t\ttotal: 50.3s\tremaining: 2m 6s\n",
      "57:\tlearn 0.6433546735\ttest 0.6332261371\tbestTest 0.6332261371\t\ttotal: 51.2s\tremaining: 2m 5s\n",
      "58:\tlearn 0.6436334145\ttest 0.6331666854\tbestTest 0.6332261371\t\ttotal: 52.2s\tremaining: 2m 4s\n",
      "59:\tlearn 0.6439603975\ttest 0.6332693431\tbestTest 0.6332693431\t\ttotal: 53.1s\tremaining: 2m 3s\n",
      "60:\tlearn 0.6443321167\ttest 0.6334163795\tbestTest 0.6334163795\t\ttotal: 54s\tremaining: 2m 2s\n",
      "61:\tlearn 0.6447388061\ttest 0.6337155694\tbestTest 0.6337155694\t\ttotal: 54.8s\tremaining: 2m 2s\n",
      "62:\tlearn 0.6450460072\ttest 0.6337961578\tbestTest 0.6337961578\t\ttotal: 55.7s\tremaining: 2m 1s\n",
      "63:\tlearn 0.645503377\ttest 0.6339695502\tbestTest 0.6339695502\t\ttotal: 56.6s\tremaining: 2m\n",
      "64:\tlearn 0.6456621093\ttest 0.633904514\tbestTest 0.6339695502\t\ttotal: 57.5s\tremaining: 1m 59s\n",
      "65:\tlearn 0.6461158026\ttest 0.6341264526\tbestTest 0.6341264526\t\ttotal: 58.5s\tremaining: 1m 58s\n",
      "66:\tlearn 0.6463800878\ttest 0.6341918181\tbestTest 0.6341918181\t\ttotal: 59.3s\tremaining: 1m 57s\n",
      "67:\tlearn 0.6465241109\ttest 0.6342237729\tbestTest 0.6342237729\t\ttotal: 1m\tremaining: 1m 56s\n",
      "68:\tlearn 0.6467670112\ttest 0.6343544404\tbestTest 0.6343544404\t\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "69:\tlearn 0.646939425\ttest 0.6344123604\tbestTest 0.6344123604\t\ttotal: 1m 2s\tremaining: 1m 55s\n",
      "70:\tlearn 0.6470859722\ttest 0.6344034447\tbestTest 0.6344123604\t\ttotal: 1m 2s\tremaining: 1m 54s\n",
      "71:\tlearn 0.6474087133\ttest 0.6343598556\tbestTest 0.6344123604\t\ttotal: 1m 3s\tremaining: 1m 53s\n",
      "72:\tlearn 0.6477509738\ttest 0.6345429449\tbestTest 0.6345429449\t\ttotal: 1m 4s\tremaining: 1m 52s\n",
      "73:\tlearn 0.6479985451\ttest 0.6345697703\tbestTest 0.6345697703\t\ttotal: 1m 5s\tremaining: 1m 51s\n",
      "74:\tlearn 0.6482028409\ttest 0.6345927439\tbestTest 0.6345927439\t\ttotal: 1m 6s\tremaining: 1m 50s\n",
      "75:\tlearn 0.6486139416\ttest 0.6347957142\tbestTest 0.6347957142\t\ttotal: 1m 7s\tremaining: 1m 50s\n",
      "76:\tlearn 0.6491064542\ttest 0.6350188895\tbestTest 0.6350188895\t\ttotal: 1m 8s\tremaining: 1m 49s\n",
      "77:\tlearn 0.6494128781\ttest 0.635068288\tbestTest 0.635068288\t\ttotal: 1m 9s\tremaining: 1m 48s\n",
      "78:\tlearn 0.6496921598\ttest 0.6351631204\tbestTest 0.6351631204\t\ttotal: 1m 10s\tremaining: 1m 47s\n",
      "79:\tlearn 0.6497144613\ttest 0.6351732897\tbestTest 0.6351732897\t\ttotal: 1m 10s\tremaining: 1m 46s\n",
      "80:\tlearn 0.6497935652\ttest 0.6352458531\tbestTest 0.6352458531\t\ttotal: 1m 11s\tremaining: 1m 45s\n",
      "81:\tlearn 0.6499369824\ttest 0.635208671\tbestTest 0.6352458531\t\ttotal: 1m 12s\tremaining: 1m 44s\n",
      "82:\tlearn 0.6501126426\ttest 0.635222381\tbestTest 0.6352458531\t\ttotal: 1m 13s\tremaining: 1m 43s\n",
      "83:\tlearn 0.6502592239\ttest 0.635226492\tbestTest 0.6352458531\t\ttotal: 1m 14s\tremaining: 1m 42s\n",
      "84:\tlearn 0.6505208103\ttest 0.6352687937\tbestTest 0.6352687937\t\ttotal: 1m 15s\tremaining: 1m 42s\n",
      "85:\tlearn 0.65090587\ttest 0.6353938566\tbestTest 0.6353938566\t\ttotal: 1m 16s\tremaining: 1m 41s\n",
      "86:\tlearn 0.6513255324\ttest 0.6354670268\tbestTest 0.6354670268\t\ttotal: 1m 17s\tremaining: 1m 40s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87:\tlearn 0.6515920553\ttest 0.6355646206\tbestTest 0.6355646206\t\ttotal: 1m 18s\tremaining: 1m 39s\n",
      "88:\tlearn 0.6518456379\ttest 0.6356922855\tbestTest 0.6356922855\t\ttotal: 1m 19s\tremaining: 1m 38s\n",
      "89:\tlearn 0.6521337232\ttest 0.6356939644\tbestTest 0.6356939644\t\ttotal: 1m 20s\tremaining: 1m 37s\n",
      "90:\tlearn 0.6525042603\ttest 0.635877195\tbestTest 0.635877195\t\ttotal: 1m 20s\tremaining: 1m 36s\n",
      "91:\tlearn 0.6529836174\ttest 0.6360302948\tbestTest 0.6360302948\t\ttotal: 1m 21s\tremaining: 1m 36s\n",
      "92:\tlearn 0.6532447353\ttest 0.6359851824\tbestTest 0.6360302948\t\ttotal: 1m 22s\tremaining: 1m 35s\n",
      "93:\tlearn 0.6534606192\ttest 0.6360043257\tbestTest 0.6360302948\t\ttotal: 1m 23s\tremaining: 1m 34s\n",
      "94:\tlearn 0.6535840837\ttest 0.6360434901\tbestTest 0.6360434901\t\ttotal: 1m 24s\tremaining: 1m 33s\n",
      "95:\tlearn 0.6538178923\ttest 0.6359832287\tbestTest 0.6360434901\t\ttotal: 1m 25s\tremaining: 1m 32s\n",
      "96:\tlearn 0.6539687216\ttest 0.6358772676\tbestTest 0.6360434901\t\ttotal: 1m 26s\tremaining: 1m 31s\n",
      "97:\tlearn 0.6542391028\ttest 0.6359444053\tbestTest 0.6360434901\t\ttotal: 1m 27s\tremaining: 1m 30s\n",
      "98:\tlearn 0.6544777465\ttest 0.6360757923\tbestTest 0.6360757923\t\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "99:\tlearn 0.6545307901\ttest 0.6360871206\tbestTest 0.6360871206\t\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "100:\tlearn 0.6546916985\ttest 0.6361174432\tbestTest 0.6361174432\t\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "101:\tlearn 0.6549357839\ttest 0.6362051387\tbestTest 0.6362051387\t\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "102:\tlearn 0.6553431819\ttest 0.6363343451\tbestTest 0.6363343451\t\ttotal: 1m 31s\tremaining: 1m 26s\n",
      "103:\tlearn 0.6557008339\ttest 0.6363456358\tbestTest 0.6363456358\t\ttotal: 1m 32s\tremaining: 1m 25s\n",
      "104:\tlearn 0.6563622131\ttest 0.6366883214\tbestTest 0.6366883214\t\ttotal: 1m 33s\tremaining: 1m 24s\n",
      "105:\tlearn 0.656494163\ttest 0.6366682226\tbestTest 0.6366883214\t\ttotal: 1m 34s\tremaining: 1m 23s\n",
      "106:\tlearn 0.6564959906\ttest 0.6366772731\tbestTest 0.6366883214\t\ttotal: 1m 34s\tremaining: 1m 22s\n",
      "107:\tlearn 0.6566042074\ttest 0.6367065131\tbestTest 0.6367065131\t\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "108:\tlearn 0.6567506637\ttest 0.6366630744\tbestTest 0.6367065131\t\ttotal: 1m 36s\tremaining: 1m 20s\n",
      "109:\tlearn 0.6569312928\ttest 0.636788888\tbestTest 0.636788888\t\ttotal: 1m 37s\tremaining: 1m 19s\n",
      "110:\tlearn 0.6570938278\ttest 0.6368195373\tbestTest 0.6368195373\t\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "111:\tlearn 0.657285033\ttest 0.6367999428\tbestTest 0.6368195373\t\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "112:\tlearn 0.6574615821\ttest 0.6369468184\tbestTest 0.6369468184\t\ttotal: 1m 40s\tremaining: 1m 17s\n",
      "113:\tlearn 0.657698226\ttest 0.636931475\tbestTest 0.6369468184\t\ttotal: 1m 41s\tremaining: 1m 16s\n",
      "114:\tlearn 0.6580153488\ttest 0.6368683511\tbestTest 0.6369468184\t\ttotal: 1m 41s\tremaining: 1m 15s\n",
      "115:\tlearn 0.6581180001\ttest 0.6368747866\tbestTest 0.6369468184\t\ttotal: 1m 42s\tremaining: 1m 14s\n",
      "116:\tlearn 0.65826152\ttest 0.6369247244\tbestTest 0.6369468184\t\ttotal: 1m 43s\tremaining: 1m 13s\n",
      "117:\tlearn 0.6582958206\ttest 0.6369307036\tbestTest 0.6369468184\t\ttotal: 1m 44s\tremaining: 1m 12s\n",
      "118:\tlearn 0.6584128755\ttest 0.6368726604\tbestTest 0.6369468184\t\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "119:\tlearn 0.658644347\ttest 0.6369521637\tbestTest 0.6369521637\t\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "120:\tlearn 0.6588132663\ttest 0.6369366258\tbestTest 0.6369521637\t\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "121:\tlearn 0.6589211668\ttest 0.6368871949\tbestTest 0.6369521637\t\ttotal: 1m 48s\tremaining: 1m 9s\n",
      "122:\tlearn 0.6590780553\ttest 0.6368563719\tbestTest 0.6369521637\t\ttotal: 1m 49s\tremaining: 1m 8s\n",
      "123:\tlearn 0.6592337062\ttest 0.6368427242\tbestTest 0.6369521637\t\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "124:\tlearn 0.6593151449\ttest 0.6368447739\tbestTest 0.6369521637\t\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "125:\tlearn 0.6597338532\ttest 0.6368464813\tbestTest 0.6369521637\t\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "126:\tlearn 0.659952649\ttest 0.6368309551\tbestTest 0.6369521637\t\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "127:\tlearn 0.6602284013\ttest 0.6368675667\tbestTest 0.6369521637\t\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "128:\tlearn 0.6603536143\ttest 0.6368967082\tbestTest 0.6369521637\t\ttotal: 1m 54s\tremaining: 1m 3s\n",
      "129:\tlearn 0.6605093149\ttest 0.6369681242\tbestTest 0.6369681242\t\ttotal: 1m 55s\tremaining: 1m 2s\n",
      "130:\tlearn 0.6605893723\ttest 0.6370257461\tbestTest 0.6370257461\t\ttotal: 1m 56s\tremaining: 1m 1s\n",
      "131:\tlearn 0.6607468045\ttest 0.6370222962\tbestTest 0.6370257461\t\ttotal: 1m 57s\tremaining: 1m\n",
      "132:\tlearn 0.6609034537\ttest 0.6369827896\tbestTest 0.6370257461\t\ttotal: 1m 58s\tremaining: 59.5s\n",
      "133:\tlearn 0.6611042736\ttest 0.6370165089\tbestTest 0.6370257461\t\ttotal: 1m 59s\tremaining: 58.6s\n",
      "134:\tlearn 0.6612658474\ttest 0.6369782547\tbestTest 0.6370257461\t\ttotal: 1m 59s\tremaining: 57.7s\n",
      "135:\tlearn 0.6613916486\ttest 0.6369985285\tbestTest 0.6370257461\t\ttotal: 2m\tremaining: 56.9s\n",
      "136:\tlearn 0.6614936288\ttest 0.6369068503\tbestTest 0.6370257461\t\ttotal: 2m 1s\tremaining: 56s\n",
      "137:\tlearn 0.6616794637\ttest 0.6370297287\tbestTest 0.6370297287\t\ttotal: 2m 2s\tremaining: 55.1s\n",
      "138:\tlearn 0.6618075154\ttest 0.637088284\tbestTest 0.637088284\t\ttotal: 2m 3s\tremaining: 54.2s\n",
      "139:\tlearn 0.661940075\ttest 0.6370822257\tbestTest 0.637088284\t\ttotal: 2m 4s\tremaining: 53.3s\n",
      "140:\tlearn 0.6619655576\ttest 0.6371003552\tbestTest 0.6371003552\t\ttotal: 2m 5s\tremaining: 52.5s\n",
      "141:\tlearn 0.6621525137\ttest 0.6370798856\tbestTest 0.6371003552\t\ttotal: 2m 6s\tremaining: 51.6s\n",
      "142:\tlearn 0.6623347446\ttest 0.6370357092\tbestTest 0.6371003552\t\ttotal: 2m 7s\tremaining: 50.7s\n",
      "143:\tlearn 0.6625995663\ttest 0.6370563798\tbestTest 0.6371003552\t\ttotal: 2m 8s\tremaining: 49.8s\n",
      "144:\tlearn 0.6627956823\ttest 0.637187759\tbestTest 0.637187759\t\ttotal: 2m 9s\tremaining: 48.9s\n",
      "145:\tlearn 0.6629993899\ttest 0.6372676006\tbestTest 0.6372676006\t\ttotal: 2m 9s\tremaining: 48.1s\n",
      "146:\tlearn 0.6633731667\ttest 0.6371613646\tbestTest 0.6372676006\t\ttotal: 2m 10s\tremaining: 47.2s\n",
      "147:\tlearn 0.6634097975\ttest 0.6371937667\tbestTest 0.6372676006\t\ttotal: 2m 11s\tremaining: 46.3s\n",
      "148:\tlearn 0.6636792754\ttest 0.6371860166\tbestTest 0.6372676006\t\ttotal: 2m 12s\tremaining: 45.4s\n",
      "149:\tlearn 0.6640092687\ttest 0.6371185871\tbestTest 0.6372676006\t\ttotal: 2m 13s\tremaining: 44.5s\n",
      "150:\tlearn 0.6641185762\ttest 0.6371558288\tbestTest 0.6372676006\t\ttotal: 2m 14s\tremaining: 43.6s\n",
      "151:\tlearn 0.6642397788\ttest 0.6372388467\tbestTest 0.6372676006\t\ttotal: 2m 15s\tremaining: 42.8s\n",
      "152:\tlearn 0.6643493906\ttest 0.6373441726\tbestTest 0.6373441726\t\ttotal: 2m 16s\tremaining: 41.9s\n",
      "153:\tlearn 0.664458128\ttest 0.6373774705\tbestTest 0.6373774705\t\ttotal: 2m 17s\tremaining: 41s\n",
      "154:\tlearn 0.6644721865\ttest 0.6374171508\tbestTest 0.6374171508\t\ttotal: 2m 18s\tremaining: 40.1s\n",
      "155:\tlearn 0.6647740585\ttest 0.6375043433\tbestTest 0.6375043433\t\ttotal: 2m 19s\tremaining: 39.2s\n",
      "156:\tlearn 0.6651162676\ttest 0.637515879\tbestTest 0.637515879\t\ttotal: 2m 19s\tremaining: 38.3s\n",
      "157:\tlearn 0.6652220099\ttest 0.6374830141\tbestTest 0.637515879\t\ttotal: 2m 20s\tremaining: 37.4s\n",
      "158:\tlearn 0.6653174599\ttest 0.6374070761\tbestTest 0.637515879\t\ttotal: 2m 21s\tremaining: 36.5s\n",
      "159:\tlearn 0.6654679608\ttest 0.6374493895\tbestTest 0.637515879\t\ttotal: 2m 22s\tremaining: 35.6s\n",
      "160:\tlearn 0.6657604108\ttest 0.6374588808\tbestTest 0.637515879\t\ttotal: 2m 23s\tremaining: 34.8s\n",
      "161:\tlearn 0.6658442326\ttest 0.637484037\tbestTest 0.637515879\t\ttotal: 2m 24s\tremaining: 33.9s\n",
      "162:\tlearn 0.6659634317\ttest 0.6374024737\tbestTest 0.637515879\t\ttotal: 2m 25s\tremaining: 33s\n",
      "163:\tlearn 0.6663378719\ttest 0.6372406566\tbestTest 0.637515879\t\ttotal: 2m 26s\tremaining: 32.1s\n",
      "164:\tlearn 0.666573783\ttest 0.6373607256\tbestTest 0.637515879\t\ttotal: 2m 27s\tremaining: 31.2s\n",
      "165:\tlearn 0.6666472446\ttest 0.63732683\tbestTest 0.637515879\t\ttotal: 2m 28s\tremaining: 30.3s\n",
      "166:\tlearn 0.6666855775\ttest 0.6372847033\tbestTest 0.637515879\t\ttotal: 2m 28s\tremaining: 29.4s\n",
      "167:\tlearn 0.6667613296\ttest 0.6373352984\tbestTest 0.637515879\t\ttotal: 2m 29s\tremaining: 28.5s\n",
      "168:\tlearn 0.6668124785\ttest 0.6373093967\tbestTest 0.637515879\t\ttotal: 2m 30s\tremaining: 27.7s\n",
      "169:\tlearn 0.6669528647\ttest 0.6372679999\tbestTest 0.637515879\t\ttotal: 2m 31s\tremaining: 26.8s\n",
      "170:\tlearn 0.6671034519\ttest 0.6373106672\tbestTest 0.637515879\t\ttotal: 2m 32s\tremaining: 25.9s\n",
      "171:\tlearn 0.6672643992\ttest 0.637252357\tbestTest 0.637515879\t\ttotal: 2m 33s\tremaining: 25s\n",
      "172:\tlearn 0.6674806201\ttest 0.6372251446\tbestTest 0.637515879\t\ttotal: 2m 34s\tremaining: 24.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173:\tlearn 0.6676710839\ttest 0.6371740322\tbestTest 0.637515879\t\ttotal: 2m 35s\tremaining: 23.2s\n",
      "174:\tlearn 0.6677267572\ttest 0.6371524321\tbestTest 0.637515879\t\ttotal: 2m 36s\tremaining: 22.3s\n",
      "175:\tlearn 0.667887388\ttest 0.6372306376\tbestTest 0.637515879\t\ttotal: 2m 37s\tremaining: 21.4s\n",
      "176:\tlearn 0.6682406453\ttest 0.6372366972\tbestTest 0.637515879\t\ttotal: 2m 38s\tremaining: 20.5s\n",
      "177:\tlearn 0.6685133478\ttest 0.6372469767\tbestTest 0.637515879\t\ttotal: 2m 38s\tremaining: 19.6s\n",
      "178:\tlearn 0.6686699018\ttest 0.6372100164\tbestTest 0.637515879\t\ttotal: 2m 39s\tremaining: 18.8s\n",
      "179:\tlearn 0.6687907129\ttest 0.6372092126\tbestTest 0.637515879\t\ttotal: 2m 40s\tremaining: 17.9s\n",
      "180:\tlearn 0.6688416176\ttest 0.6371799272\tbestTest 0.637515879\t\ttotal: 2m 41s\tremaining: 17s\n",
      "181:\tlearn 0.6689610741\ttest 0.6372016478\tbestTest 0.637515879\t\ttotal: 2m 42s\tremaining: 16.1s\n",
      "182:\tlearn 0.6691249772\ttest 0.6372129023\tbestTest 0.637515879\t\ttotal: 2m 43s\tremaining: 15.2s\n",
      "183:\tlearn 0.6694203218\ttest 0.6371998885\tbestTest 0.637515879\t\ttotal: 2m 44s\tremaining: 14.3s\n",
      "184:\tlearn 0.6695087858\ttest 0.637301058\tbestTest 0.637515879\t\ttotal: 2m 45s\tremaining: 13.4s\n",
      "185:\tlearn 0.669686565\ttest 0.6373598116\tbestTest 0.637515879\t\ttotal: 2m 46s\tremaining: 12.5s\n",
      "186:\tlearn 0.6698874936\ttest 0.6374191473\tbestTest 0.637515879\t\ttotal: 2m 47s\tremaining: 11.6s\n",
      "187:\tlearn 0.6700507118\ttest 0.6374633717\tbestTest 0.637515879\t\ttotal: 2m 48s\tremaining: 10.7s\n",
      "188:\tlearn 0.6702001149\ttest 0.6375511099\tbestTest 0.6375511099\t\ttotal: 2m 48s\tremaining: 9.83s\n",
      "189:\tlearn 0.6702799881\ttest 0.6375301101\tbestTest 0.6375511099\t\ttotal: 2m 49s\tremaining: 8.94s\n",
      "190:\tlearn 0.6703880991\ttest 0.637527971\tbestTest 0.6375511099\t\ttotal: 2m 50s\tremaining: 8.05s\n",
      "191:\tlearn 0.6704674831\ttest 0.6375394899\tbestTest 0.6375511099\t\ttotal: 2m 51s\tremaining: 7.16s\n",
      "192:\tlearn 0.6705486489\ttest 0.6374528679\tbestTest 0.6375511099\t\ttotal: 2m 52s\tremaining: 6.26s\n",
      "193:\tlearn 0.6707236436\ttest 0.6374306598\tbestTest 0.6375511099\t\ttotal: 2m 53s\tremaining: 5.37s\n",
      "194:\tlearn 0.6709487493\ttest 0.6374801632\tbestTest 0.6375511099\t\ttotal: 2m 54s\tremaining: 4.47s\n",
      "195:\tlearn 0.6710817788\ttest 0.6374467875\tbestTest 0.6375511099\t\ttotal: 2m 55s\tremaining: 3.58s\n",
      "196:\tlearn 0.671279276\ttest 0.6374324411\tbestTest 0.6375511099\t\ttotal: 2m 56s\tremaining: 2.68s\n",
      "197:\tlearn 0.6713975828\ttest 0.6374049798\tbestTest 0.6375511099\t\ttotal: 2m 57s\tremaining: 1.79s\n",
      "198:\tlearn 0.6714403507\ttest 0.6373367219\tbestTest 0.6375511099\t\ttotal: 2m 58s\tremaining: 895ms\n",
      "199:\tlearn 0.6715058234\ttest 0.6373288551\tbestTest 0.6375511099\t\ttotal: 2m 58s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6375511099\n",
      "bestIteration = 188\n",
      "\n",
      "Shrink model to first 189 iterations.\n",
      "0.275102219885\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn import *\n",
    "# from catboost import CatBoostClassifier\n",
    "# from multiprocessing import *\n",
    "\n",
    "# train = pd.read_csv(base_path + 'train_p.csv')\n",
    "# test = pd.read_csv(base_path + 'test_p.csv')\n",
    "# col = [c for c in train.columns if c not in ['id','target']]\n",
    "# print(len(col))\n",
    "# col = [c for c in col if not c.startswith('ps_calc_')]\n",
    "# print(len(col))\n",
    "\n",
    "# train = train.replace(-1, np.NaN)\n",
    "# d_median = train.median(axis=0)\n",
    "# d_mean = train.mean(axis=0)\n",
    "# train = train.fillna(-1)\n",
    "\n",
    "# def transform_df(df):\n",
    "#     df = pd.DataFrame(df)\n",
    "#     dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "#     df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "#     df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "#     for c in dcol:\n",
    "#         if '_bin' not in c: #standard arithmetic\n",
    "#             df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "#             df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "#             #df[c+str('_sq')] = np.power(df[c].values,2).astype(np.float32)\n",
    "#             #df[c+str('_sqr')] = np.square(df[c].values).astype(np.float32)\n",
    "#             #df[c+str('_log')] = np.log(np.abs(df[c].values) + 1)\n",
    "#             #df[c+str('_exp')] = np.exp(df[c].values) - 1\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# def multi_transform(df):\n",
    "#     print('Init Shape: ', df.shape)\n",
    "#     #p = Pool(cpu_count())\n",
    "#     df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "#     df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "#     #p.close(); p.join()\n",
    "#     print('After Shape: ', df.shape)\n",
    "#     return df\n",
    "\n",
    "# def gini(y, pred):\n",
    "#     fpr, tpr, thr = metrics.roc_curve(y, pred, pos_label=1)\n",
    "#     g = 2 * metrics.auc(fpr, tpr) -1\n",
    "#     return g\n",
    "\n",
    "# def gini_catboost(pred, y):\n",
    "#     return gini(y, pred)\n",
    "\n",
    "# x1, x2, y1, y2 = model_selection.train_test_split(train, train['target'], test_size=0.25, random_state=99)\n",
    "\n",
    "# x1 = transform_df(x1)\n",
    "# x2 = transform_df(x2)\n",
    "# test = transform_df(test)\n",
    "# train = transform_df(train)\n",
    "\n",
    "# col = [c for c in x1.columns if c not in ['id','target']]\n",
    "# col = [c for c in col if not c.startswith('ps_calc_')]\n",
    "# print(x1.values.shape, x2.values.shape)\n",
    "\n",
    "# #remove duplicates just in case\n",
    "# #tdups = transform_df(train)\n",
    "# #dups = tdups[tdups.duplicated(subset=col, keep=False)]\n",
    "\n",
    "# #x1 = x1[~(x1['id'].isin(dups['id'].values))]\n",
    "# #x2 = x2[~(x2['id'].isin(dups['id'].values))]\n",
    "# #print(x1.values.shape, x2.values.shape)\n",
    "\n",
    "# y1 = x1['target']\n",
    "# y2 = x2['target']\n",
    "# x1 = x1[col]\n",
    "# x2 = x2[col]\n",
    "\n",
    "# model3 = CatBoostClassifier(iterations=200, learning_rate=0.1, depth=7, loss_function='Logloss', eval_metric='AUC', random_seed=0, od_type='Iter', od_wait=100) \n",
    "# model3.fit(x1[col], y1, eval_set=(x2[col], y2), use_best_model=True, verbose=True, )\n",
    "# print(gini_catboost(model3.predict_proba(x2[col])[:,1], y2))\n",
    "# test['target'] = model3.predict_proba(test[col])[:,1]\n",
    "# test['target'] = (np.exp(test['target'].values) - 1.0).clip(0,1)\n",
    "# train['target'] = model3.predict_proba(train[col])[:,1]\n",
    "# train['target'] = (np.exp(train['target'].values) - 1.0).clip(0,1)\n",
    "# test[['id','target']].to_csv(base_path + 'test_catboost_submission.csv', index=False, float_format='%.5f')\n",
    "# train[['id','target']].to_csv(base_path + 'train_catboost_submission.csv', index=False, float_format='%.5f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892816\n",
      "892816\n",
      "892816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test files\n",
    "stack1 = pd.read_csv('stacked_1.csv')\n",
    "test_xgb = pd.read_csv(base_path + 'test_sub_xgb.csv')\n",
    "test_lgb = pd.read_csv(base_path + 'test_sub_lgb.csv')\n",
    "# test_dnn = pd.read_csv(base_path + 'test_dnn_predictions.csv')\n",
    "# test_up = pd.read_csv(base_path + 'test_submission.csv')\n",
    "#test_cat = pd.read_csv(base_path + 'test_catboost_submission.csv')\n",
    "# test_kin = pd.read_csv(base_path + 'test_uberKinetics.csv')\n",
    "# test_gp = pd.read_csv(base_path + 'test_gpari.csv')\n",
    "\n",
    "test=pd.read_csv(base_path + 'test.csv')\n",
    "\n",
    "\n",
    "test = pd.concat([test, \n",
    "                   test_xgb[['target']].rename(columns = {'target' : 'xgb'}),\n",
    "                   test_lgb[['target']].rename(columns = {'target' : 'lgb'}),\n",
    "#                    test_dnn[['target']].rename(columns = {'target' : 'dnn'}),\n",
    "#                    test_up[['target']].rename(columns = {'target' : 'up'}),\n",
    "#                 test_cat[['target']].rename(columns = {'target' : 'cat'}),\n",
    "#                    test_kin[['target']].rename(columns = {'target' : 'kin'}),\n",
    "#                    test_gp[['target']].rename(columns = {'target' : 'gp'})\n",
    "                  stack1[['target']].rename(columns = {'target' : 'stack'})\n",
    "                  ], axis = 1)\n",
    "\n",
    "train_cols = ['xgb', 'lgb', 'stack']\n",
    "#train_cols = ['xgb', 'lgb', 'dnn', 'up', 'cat', 'kin', 'gp']\n",
    "\n",
    "for t in train_cols:\n",
    "    test[t + '_rank'] = test[t].rank()\n",
    "\n",
    "for t in train_cols:\n",
    "    test[t + '_rank'] = test[t].rank()\n",
    "print(len(test['xgb']))\n",
    "print(len(test['lgb']))\n",
    "print(len(test['stack']))\n",
    "\n",
    "test['target'] = test[['xgb', 'lgb', 'stack']].mean(axis=1)\n",
    "#test['target'] = (test['xgb_rank'] + test['lgb_rank'] +test['stack_rank'])/(3 * test.shape[0])\n",
    "#test['target'] = (test['xgb_rank'] + test['lgb_rank'] + test['dnn_rank'] + test['up_rank'] + \\\n",
    "#                  test['cat_rank'] + test['kin_rank'] + test['gp_rank']) / (7 * test.shape[0])\n",
    "test[['id', 'target']].to_csv(base_path + 'rank_avg_lgbm_xgb_stack1_mean.csv.gz', index = False, compression = 'gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.037978\n",
       "1         0.038960\n",
       "2         0.040280\n",
       "3         0.026478\n",
       "4         0.050264\n",
       "5         0.061672\n",
       "6         0.028356\n",
       "7         0.049340\n",
       "8         0.072645\n",
       "9         0.081197\n",
       "10        0.042372\n",
       "11        0.034988\n",
       "12        0.058952\n",
       "13        0.061919\n",
       "14        0.064996\n",
       "15        0.032561\n",
       "16        0.036719\n",
       "17        0.076335\n",
       "18        0.025975\n",
       "19        0.081280\n",
       "20        0.050651\n",
       "21        0.075079\n",
       "22        0.081409\n",
       "23        0.027450\n",
       "24        0.037788\n",
       "25        0.037604\n",
       "26        0.142415\n",
       "27        0.059298\n",
       "28        0.037157\n",
       "29        0.028136\n",
       "            ...   \n",
       "892786    0.028708\n",
       "892787    0.046325\n",
       "892788    0.047847\n",
       "892789    0.048604\n",
       "892790    0.048138\n",
       "892791    0.039376\n",
       "892792    0.039212\n",
       "892793    0.055495\n",
       "892794    0.036357\n",
       "892795    0.048241\n",
       "892796    0.082164\n",
       "892797    0.098439\n",
       "892798    0.052594\n",
       "892799    0.151616\n",
       "892800    0.038086\n",
       "892801    0.040711\n",
       "892802    0.040772\n",
       "892803    0.044280\n",
       "892804    0.066957\n",
       "892805    0.045834\n",
       "892806    0.037194\n",
       "892807    0.038422\n",
       "892808    0.036923\n",
       "892809    0.027952\n",
       "892810    0.034642\n",
       "892811    0.147762\n",
       "892812    0.057548\n",
       "892813    0.055488\n",
       "892814    0.035426\n",
       "892815    0.042532\n",
       "Length: 892816, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150    0.188827\n",
       "151    0.027185\n",
       "152    0.053618\n",
       "153    0.028737\n",
       "154    0.026434\n",
       "155    0.070561\n",
       "156    0.075738\n",
       "157    0.043073\n",
       "158    0.038377\n",
       "159    0.044140\n",
       "160    0.121006\n",
       "161    0.035458\n",
       "162    0.042560\n",
       "163    0.033056\n",
       "164    0.044098\n",
       "165    0.024820\n",
       "166    0.036434\n",
       "167    0.036668\n",
       "168    0.024154\n",
       "169    0.086391\n",
       "170    0.045251\n",
       "171    0.071042\n",
       "172    0.079558\n",
       "173    0.073117\n",
       "174    0.047517\n",
       "175    0.050846\n",
       "176    0.031933\n",
       "177    0.038984\n",
       "178    0.100594\n",
       "179    0.042305\n",
       "180    0.078455\n",
       "181    0.040199\n",
       "182    0.092254\n",
       "183    0.041887\n",
       "184    0.044591\n",
       "185    0.040523\n",
       "186    0.144497\n",
       "187    0.060536\n",
       "188    0.047316\n",
       "189    0.041010\n",
       "190    0.101201\n",
       "191    0.038987\n",
       "192    0.305332\n",
       "193    0.041176\n",
       "194    0.089928\n",
       "195    0.027068\n",
       "196    0.053228\n",
       "197    0.053064\n",
       "198    0.140266\n",
       "199    0.048396\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
